{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from pickle import dump ,load\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./trainData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertainment 384\n",
      "sport 508\n",
      "politics 414\n",
      "tech 398\n",
      "business 508\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(columns=['Text']) \n",
    "for folders in os.listdir(os.getcwd()):\n",
    "    cnt=0\n",
    "    for file in os.listdir(folders):\n",
    "        data=data.append({'Text':codecs.open('./'+folders+'/'+file,encoding='utf8',\\\n",
    "                    errors='replace').read()},ignore_index=True)\n",
    "        cnt+=1\n",
    "    print(folders,cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Musicians to tackle US red tape\\n\\nMusicians' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sideways dominates Spirit awards\\n\\nThe comedy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bennett play takes theatre prizes\\n\\nThe Histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock group Korn's guitarist quits\\n\\nThe guita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rocker Doherty in on-stage fight\\n\\nRock singe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Musicians to tackle US red tape\\n\\nMusicians' ...\n",
       "1  Sideways dominates Spirit awards\\n\\nThe comedy...\n",
       "2  Bennett play takes theatre prizes\\n\\nThe Histo...\n",
       "3  Rock group Korn's guitarist quits\\n\\nThe guita...\n",
       "4  Rocker Doherty in on-stage fight\\n\\nRock singe..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(data.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['Text']=data['Text'].apply(lambda x : re.sub(\"[(),!?@\\'\\`\\\"\\_:.#%]\",'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Sideways dominates Spirit awards\\n\\nThe comedy...\n",
       "2    Bennett play takes theatre prizes\\n\\nThe Histo...\n",
       "3    Rock group Korn's guitarist quits\\n\\nThe guita...\n",
       "4    Rocker Doherty in on-stage fight\\n\\nRock singe...\n",
       "5    Manics in charge of BBC 6 Music\\n\\nThe Manic S...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['head_lines']=data['Text'].apply(lambda x: 'startseq '+x.splitlines()[0]+' endseq')\n",
    "data['Text']=data['Text'].apply(lambda x: 'startseq '+' '.join(x.splitlines()[1:])+' endseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"startseq  The comedy Sideways has dominated this year's Independent Spirit Awards, winning all six of the awards for which it was nominated.  It was named best film while Alexander Payne won best director and best screenplay, along with writing partner Jim Taylor. It also won acting awards for stars Paul Giamatti, Thomas Haden Church and Virginia Madsen. Sideways is tipped to do well at Sunday's Oscars, with five nominations.  The awards, now in their 20th year, are given to films made outside the traditional studio system, and are traditionally held the day before the Oscars. Other winners included Catalina Sandino Moreno, who took best actress for her role as a drug smuggler in the Colombian drama Maria Full of Grace. Moreno is also nominated for best actress at the Oscars. The best first screenplay award went to Joshua Marston for Maria Full of Grace. Scrubs star Zach Braff won the award for best first feature for Garden State, which he wrote, directed and starred in. Oscar-nominated euthanasia film The Sea Inside from Spain won best foreign film, while Metallica: Some Kind Of Monster was awarded best documentary. Actor Rodrigo de la Serna took the best debut performance prize for The Motorcycle Diaries. The awards are voted for by the 9,000 members of the Independent Feature Project/Los Angeles, which includes actors, directors, writers and other industry professionals. Last year's big winner, Lost In Translation, went on to win the Oscar for best original screenplay, for writer-director Sofia Coppola. endseq\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>head_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>startseq  One in 10 adult Americans - equivale...</td>\n",
       "      <td>startseq Millions buy MP3 players in US endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>startseq  India has signed a $40bn (£21bn) dea...</td>\n",
       "      <td>startseq India and Iran in gas export deal endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>startseq  If there is one thing certain to sti...</td>\n",
       "      <td>startseq Labour MPs' fears over squabbling endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>startseq  Peace protestors have lost a landmar...</td>\n",
       "      <td>startseq Peace demo appeal rejected endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>startseq  Albania, Bulgaria and Macedonia has ...</td>\n",
       "      <td>startseq Go-ahead for Balkan oil pipeline endseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  startseq  One in 10 adult Americans - equivale...   \n",
       "1  startseq  India has signed a $40bn (£21bn) dea...   \n",
       "2  startseq  If there is one thing certain to sti...   \n",
       "3  startseq  Peace protestors have lost a landmar...   \n",
       "4  startseq  Albania, Bulgaria and Macedonia has ...   \n",
       "\n",
       "                                          head_lines  \n",
       "0     startseq Millions buy MP3 players in US endseq  \n",
       "1  startseq India and Iran in gas export deal endseq  \n",
       "2  startseq Labour MPs' fears over squabbling endseq  \n",
       "3         startseq Peace demo appeal rejected endseq  \n",
       "4   startseq Go-ahead for Balkan oil pipeline endseq  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(filters='!\"#$%&()*+,\\'-./:;<=>?@[\\\\]^_`{|}~\\t\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(data['head_lines'].tolist()+data['Text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29664\n"
     ]
    }
   ],
   "source": [
    "word_to_index=tokenizer.word_index\n",
    "index_to_word={ index:word for word,index in word_to_index.items()}\n",
    "vocab_size=len(word_to_index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(word_to_index,open('word_to_index.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence_text=tokenizer.texts_to_sequences(data[\"Text\"].tolist())\n",
    "train_sequence_head=tokenizer.texts_to_sequences(data[\"head_lines\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4489 11\n"
     ]
    }
   ],
   "source": [
    "maxlen_x=max(len(i) for i in train_sequence_text)\n",
    "maxlen_y=max(len(i) for i in train_sequence_head)\n",
    "print(maxlen_x,maxlen_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_model(sequences_head,sequences_text):\n",
    "    x1=[]\n",
    "    x2=[]\n",
    "    y=[]\n",
    "    for sequence_idx,sequence in enumerate(sequences_head):\n",
    "        for idx in range(1,len(sequence)):\n",
    "            in_seq,out_seq=sequence[:idx],sequence[idx]\n",
    "            in_seq=pad_sequences([in_seq],maxlen=maxlen_y)[0]\n",
    "            out_seq=to_categorical([out_seq],num_classes=vocab_size+1)[0]\n",
    "            x1.append(pad_sequences([sequences_text[sequence_idx]],maxlen=maxlen_x)[0])\n",
    "            x2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(x1),np.array(x2),np.array(y)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train,x2_train,y_train=data_for_model(train_sequence_head,train_sequence_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(x1_train, open('x1_train.pkl', 'wb'))\n",
    "dump(x2_train, open('x2_train.pkl', 'wb'))\n",
    "dump(y_train, open('y_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aninda/protoTypeProject/nlp/Auto Headline Generator Using LSTM'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=200\n",
    "embedding_weights = np.empty((400000,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "glove_index_dict = {}\n",
    "with open('glove.6B.200d.txt','r') as file:\n",
    "    for line in file:\n",
    "        token=line.strip().split()\n",
    "        glove_index_dict[token[0]] = i\n",
    "        embedding_weights[i,:]=list(map(float,token[1:]))\n",
    "        #print(i)\n",
    "        i+=1\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "embedding_weights*=.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0661404484678092\n"
     ]
    }
   ],
   "source": [
    "shape=(vocab_size+1,200)\n",
    "scale = embedding_weights.std()*np.sqrt(12)/2\n",
    "print(scale)\n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for word,idx in word_to_index.items():\n",
    "    if word in glove_index_dict:\n",
    "        embedding[idx,:] = embedding_weights[glove_index_dict[word],:]\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_rnn_size = 40 \n",
    "rnn_size = 512 # must be same as 160330-word-gen\n",
    "rnn_layers = 3  # match FN1\n",
    "batch_norm=False\n",
    "seed=42\n",
    "p_W, p_U, p_dense, weight_decay = 0, 0, 0, 0\n",
    "optimizer = 'adam'\n",
    "LR = 1e-4\n",
    "batch_size=64\n",
    "nflips=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model,save_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = l2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 23:36:45.065155 140011615065920 deprecation.py:323] From /home/aninda/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3868: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             [(None, 4489)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 11)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_em (Embedding)             (None, 4489, 200)    5933000     input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "head_em (Embedding)             (None, 11, 200)      5933000     input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "text_drop (Dropout)             (None, 4489, 200)    0           text_em[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "head_drop (Dropout)             (None, 11, 200)      0           head_em[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text_lstm2 (LSTM)               (None, 12)           10224       text_drop[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_lstm1 (LSTM)               (None, 12)           10224       head_drop[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_add (Add)               (None, 12)           0           text_lstm2[0][0]                 \n",
      "                                                                 head_lstm1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dence1 (Dense)          (None, 256)          3328        decoder_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dence2 (Dense)          (None, 29665)        7623905     decoder_dence1[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 19,513,681\n",
      "Trainable params: 19,513,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input1 = Input(shape=(maxlen_x,),name='input1')\n",
    "text_em = Embedding(vocab_size+1, 200,weights=[embedding],embeddings_regularizer=regularizer,\\\n",
    "                    mask_zero=True,name='text_em')(input1)\n",
    "text_drop=Dropout(.5,name='text_drop')(text_em)\n",
    "#text_lstm1= LSTM(600,activation='relu',return_sequences=True,dropout=.5,kernel_regularizer=regularizer ,name='text_lstm')(text_drop)\n",
    "#text_lstm2= LSTM(30,activation='relu',return_sequences=True,dropout=.5,kernel_regularizer=regularizer ,name='text_lstm1')(text_drop)\n",
    "text_lstm3= LSTM(12,activation='relu',dropout=.5,kernel_regularizer=regularizer ,name='text_lstm2')(text_drop)\n",
    "\n",
    "\n",
    "#encoder13 = RepeatVector(sum_txt_length)(encoder2)\n",
    "\n",
    "input2 = Input(shape=(maxlen_y,),name='input2')\n",
    "head_em = Embedding(vocab_size+1, 200,weights=[embedding],embeddings_regularizer=regularizer,\\\n",
    "                    mask_zero=True,name='head_em')(input2)\n",
    "head_drop=Dropout(.5,name='head_drop')(head_em)\n",
    "head_lstm1 = LSTM(12,dropout=.5,activation='relu',kernel_regularizer=regularizer ,name='head_lstm1')(head_drop)\n",
    "#head_lstm2= LSTM(30,activation='relu',dropout=.5,kernel_regularizer=regularizer ,name='head_lstm2')(head_lstm1)\n",
    "#encoder23 = RepeatVector(sum_txt_length)(encoder2)\n",
    "\n",
    "decoder_add = add([text_lstm3,head_lstm1],name='decoder_add')\n",
    "decoder_lstm= Dense(256,activation='relu',name='decoder_dence1')(decoder_add)\n",
    "output = Dense(vocab_size+1, activation='softmax',name='decoder_dence2')(decoder_lstm)\n",
    "# tie it together\n",
    "model = Model(inputs=[input1,input2], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([x1_train,x2_train],y_train,verbose=2,batch_size=20,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model,load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aninda/protoTypeProject/nlp/Auto Headline Generator Using LSTM'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "060.txt\n",
      "026.txt\n",
      "043.txt\n",
      "207.txt\n",
      "323.txt\n",
      "063.txt\n",
      "183.txt\n",
      "057.txt\n",
      "051.txt\n",
      "111.txt\n",
      "037.txt\n",
      "119.txt\n",
      "028.txt\n",
      "001.txt\n",
      "188.txt\n"
     ]
    }
   ],
   "source": [
    "test=pd.DataFrame(columns=['Text']) \n",
    "cnt=0\n",
    "for file in os.listdir('./testData'):\n",
    "    test=test.append({'Text':codecs.open('./testData/'+file,encoding='utf8',errors='replace').read()},ignore_index=True)\n",
    "    cnt+=1\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['head_lines']=test['Text'].apply(lambda x: 'startseq '+x.splitlines()[0]+' endseq')\n",
    "test['Text']=test['Text'].apply(lambda x: 'startseq '+' '.join(list(filter(bool,x.splitlines()))[1:])+' endseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence_text=tokenizer.texts_to_sequences(test[\"Text\"].tolist())\n",
    "test1=pad_sequences([test_sequence_text[1]],maxlen=1247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   6, 220,  25]], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   1, 152,  19]], dtype=int32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1=pad_sequences([train_sequence_text[45]],maxlen=maxlen_x)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_description(model,tokenizer,doc,mx_len=9,):\n",
    "    in_text='startseq'\n",
    "    #print(type(tokenizer))\n",
    "    for i in range(mx_len):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=mx_len)\n",
    "        pred = model.predict([doc,sequence], verbose=0)\n",
    "        pred=np.argmax(pred)\n",
    "        print(pred)\n",
    "        pred_word=index_to_word[pred]\n",
    "        in_text+=' '+pred_word\n",
    "        if pred_word=='endseq' or pred_word is None:\n",
    "            break\n",
    "    in_text=' '.join(in_text.split()[1:-1])\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[0,958] = 13310 is not in [0, 6222)\n\t [[Node: text_em_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](text_em_1/embeddings/read, text_em_1/Cast)]]\n\nCaused by op 'text_em_1/Gather', defined at:\n  File \"/home/aninda/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/aninda/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-66-4d78ab440d00>\", line 1, in <module>\n    model1 = load_model('model.h5')\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/models.py\", line 243, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/models.py\", line 317, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\", line 144, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 2520, in from_config\n    process_node(layer, node_data)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 2477, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2409, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1219, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0,958] = 13310 is not in [0, 6222)\n\t [[Node: text_em_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](text_em_1/embeddings/read, text_em_1/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,958] = 13310 is not in [0, 6222)\n\t [[Node: text_em_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](text_em_1/embeddings/read, text_em_1/Cast)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e72e7fdf8acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-2795db6c7010>\u001b[0m in \u001b[0;36mpred_description\u001b[0;34m(model, tokenizer, doc, mx_len)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmx_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1842\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1335\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[0,958] = 13310 is not in [0, 6222)\n\t [[Node: text_em_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](text_em_1/embeddings/read, text_em_1/Cast)]]\n\nCaused by op 'text_em_1/Gather', defined at:\n  File \"/home/aninda/anaconda3/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/aninda/anaconda3/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-66-4d78ab440d00>\", line 1, in <module>\n    model1 = load_model('model.h5')\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/models.py\", line 243, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/models.py\", line 317, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\", line 144, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 2520, in from_config\n    process_node(layer, node_data)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 2477, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 138, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 1208, in gather\n    return tf.gather(reference, indices)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 2409, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1219, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/aninda/anaconda3/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[0,958] = 13310 is not in [0, 6222)\n\t [[Node: text_em_1/Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](text_em_1/embeddings/read, text_em_1/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "a=pred_description(model1,tokenizer,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'endseq'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size+1, 100,\n",
    "                    input_length=59,\n",
    "                    embeddings_regularizer=regularizer,  mask_zero=True,\n",
    "                    name='embedding_1'))\n",
    "\n",
    "for i in range(rnn_layers):\n",
    "    lstm = LSTM(512, return_sequences=True, # batch_norm=batch_norm,\n",
    "                kernel_regularizer=regularizer, recurrent_regularizer=regularizer,\n",
    "                bias_regularizer=regularizer, dropout=p_W, recurrent_dropout=p_U,\n",
    "                name='lstm_%d'%(i+1)\n",
    "                  )\n",
    "    model.add(lstm)\n",
    "    model.add(Dropout(p_dense,name='dropout_%d'%(i+1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_context(X, mask, n=activation_rnn_size, maxlend=maxlen_x, maxlenh=maxlen_y):\n",
    "    desc, head = X[:,:maxlend,:], X[:,maxlend:,:]\n",
    "    head_activations, head_words = head[:,:,:n], head[:,:,n:]\n",
    "    desc_activations, desc_words = desc[:,:,:n], desc[:,:,n:]\n",
    "    \n",
    "    # RTFM http://deeplearning.net/software/theano/library/tensor/basic.html#theano.tensor.batched_tensordot\n",
    "    # activation for every head word and every desc word\n",
    "    activation_energies = K.batch_dot(head_activations, desc_activations, axes=(2,2))\n",
    "    # make sure we dont use description words that are masked out\n",
    "    #activation_energies = activation_energies + -1e20*K.expand_dims(1.-K.cast(mask[:, :maxlend],'float32'),1)\n",
    "    \n",
    "    # for every head word compute weights for every desc word\n",
    "    activation_energies = K.reshape(activation_energies,(-1,maxlend))\n",
    "    activation_weights = K.softmax(activation_energies)\n",
    "    activation_weights = K.reshape(activation_weights,(-1,maxlenh,maxlend))\n",
    "\n",
    "    # for every head word compute weighted average of desc words\n",
    "    desc_avg_word = K.batch_dot(activation_weights, desc_words, axes=(2,1))\n",
    "    return K.concatenate((desc_avg_word, head_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation_rnn_size:\n",
    "    model.add(Lambda(simple_context,\n",
    "                     mask = lambda inputs, mask: mask[:,maxlen_x:],\n",
    "                     output_shape = lambda input_shape: ( input_shape[0],maxlen_y, 2*(rnn_size - activation_rnn_size)),\n",
    "                     name='simplecontext_1'))\n",
    "model.add(TimeDistributed(Dense(vocab_size,\n",
    "                                kernel_regularizer=regularizer, bias_regularizer=regularizer,\n",
    "                                name = 'timedistributed_1')))\n",
    "model.add(Activation('softmax', name='activation_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 59, 100)           2972800   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 59, 512)           1255424   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 59, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 59, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 59, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 59, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 59, 512)           0         \n",
      "_________________________________________________________________\n",
      "simplecontext_1 (Lambda)     (None, 9, 944)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 9, 29727)          28092015  \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 9, 29727)          0         \n",
      "=================================================================\n",
      "Total params: 36,518,639\n",
      "Trainable params: 36,518,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#optimizer = Adam(lr=0.0002)\n",
    "#K.set_value(model.optimizer.lr,np.float32(LR))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1780/1780 [==============================] - 303s 170ms/step - loss: 7.8262\n",
      "Epoch 2/3\n",
      "1780/1780 [==============================] - 307s 173ms/step - loss: 5.6092\n",
      "Epoch 3/3\n",
      "1780/1780 [==============================] - 294s 165ms/step - loss: 5.4654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6033aba978>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4.3094853e-01, 1.7662477e-03, 1.9458616e-02, ...,\n",
       "         3.0865652e-09, 3.1480067e-09, 3.2910128e-09],\n",
       "        [4.3094870e-01, 1.7662467e-03, 1.9458607e-02, ...,\n",
       "         3.0865666e-09, 3.1479961e-09, 3.2910141e-09],\n",
       "        [4.3094870e-01, 1.7662467e-03, 1.9458607e-02, ...,\n",
       "         3.0865666e-09, 3.1479961e-09, 3.2910141e-09],\n",
       "        ...,\n",
       "        [4.3094853e-01, 1.7662477e-03, 1.9458616e-02, ...,\n",
       "         3.0865652e-09, 3.1480067e-09, 3.2910128e-09],\n",
       "        [4.3094879e-01, 1.7662471e-03, 1.9458620e-02, ...,\n",
       "         3.0865555e-09, 3.1479908e-09, 3.2910026e-09],\n",
       "        [4.3094853e-01, 1.7662477e-03, 1.9458616e-02, ...,\n",
       "         3.0865652e-09, 3.1480067e-09, 3.2910128e-09]],\n",
       "\n",
       "       [[4.3095508e-01, 1.7662384e-03, 1.9458709e-02, ...,\n",
       "         3.0863825e-09, 3.1477965e-09, 3.2907930e-09],\n",
       "        [4.3095508e-01, 1.7662384e-03, 1.9458709e-02, ...,\n",
       "         3.0863825e-09, 3.1477965e-09, 3.2907930e-09],\n",
       "        [4.3095508e-01, 1.7662384e-03, 1.9458709e-02, ...,\n",
       "         3.0863825e-09, 3.1477965e-09, 3.2907930e-09],\n",
       "        ...,\n",
       "        [4.3095508e-01, 1.7662384e-03, 1.9458709e-02, ...,\n",
       "         3.0863825e-09, 3.1477965e-09, 3.2907930e-09],\n",
       "        [4.3095508e-01, 1.7662384e-03, 1.9458709e-02, ...,\n",
       "         3.0863825e-09, 3.1477965e-09, 3.2907930e-09],\n",
       "        [4.3095490e-01, 1.7662393e-03, 1.9458702e-02, ...,\n",
       "         3.0863871e-09, 3.1478011e-09, 3.2907983e-09]],\n",
       "\n",
       "       [[4.3094915e-01, 1.7662486e-03, 1.9458616e-02, ...,\n",
       "         3.0865639e-09, 3.1479872e-09, 3.2910055e-09],\n",
       "        [4.3094954e-01, 1.7662484e-03, 1.9458616e-02, ...,\n",
       "         3.0865550e-09, 3.1479841e-09, 3.2909957e-09],\n",
       "        [4.3094954e-01, 1.7662484e-03, 1.9458616e-02, ...,\n",
       "         3.0865550e-09, 3.1479841e-09, 3.2909957e-09],\n",
       "        ...,\n",
       "        [4.3094915e-01, 1.7662486e-03, 1.9458616e-02, ...,\n",
       "         3.0865639e-09, 3.1479872e-09, 3.2910055e-09],\n",
       "        [4.3094915e-01, 1.7662486e-03, 1.9458616e-02, ...,\n",
       "         3.0865639e-09, 3.1479872e-09, 3.2910055e-09],\n",
       "        [4.3094915e-01, 1.7662486e-03, 1.9458616e-02, ...,\n",
       "         3.0865639e-09, 3.1479872e-09, 3.2910055e-09]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[4.3095452e-01, 1.7662392e-03, 1.9458702e-02, ...,\n",
       "         3.0863962e-09, 3.1478102e-09, 3.2908074e-09],\n",
       "        [4.3095478e-01, 1.7662395e-03, 1.9458704e-02, ...,\n",
       "         3.0863923e-09, 3.1478122e-09, 3.2908094e-09],\n",
       "        [4.3095428e-01, 1.7662401e-03, 1.9458709e-02, ...,\n",
       "         3.0864005e-09, 3.1478145e-09, 3.2908123e-09],\n",
       "        ...,\n",
       "        [4.3095428e-01, 1.7662401e-03, 1.9458709e-02, ...,\n",
       "         3.0864005e-09, 3.1478145e-09, 3.2908123e-09],\n",
       "        [4.3095452e-01, 1.7662392e-03, 1.9458702e-02, ...,\n",
       "         3.0863962e-09, 3.1478102e-09, 3.2908074e-09],\n",
       "        [4.3095428e-01, 1.7662401e-03, 1.9458709e-02, ...,\n",
       "         3.0864005e-09, 3.1478145e-09, 3.2908123e-09]],\n",
       "\n",
       "       [[4.3096200e-01, 1.7662322e-03, 1.9458825e-02, ...,\n",
       "         3.0861791e-09, 3.1475886e-09, 3.2905634e-09],\n",
       "        [4.3096200e-01, 1.7662322e-03, 1.9458825e-02, ...,\n",
       "         3.0861791e-09, 3.1475886e-09, 3.2905634e-09],\n",
       "        [4.3096200e-01, 1.7662322e-03, 1.9458825e-02, ...,\n",
       "         3.0861791e-09, 3.1475886e-09, 3.2905634e-09],\n",
       "        ...,\n",
       "        [4.3096200e-01, 1.7662322e-03, 1.9458825e-02, ...,\n",
       "         3.0861791e-09, 3.1475886e-09, 3.2905634e-09],\n",
       "        [4.3096200e-01, 1.7662322e-03, 1.9458825e-02, ...,\n",
       "         3.0861791e-09, 3.1475886e-09, 3.2905634e-09],\n",
       "        [4.3096200e-01, 1.7662322e-03, 1.9458825e-02, ...,\n",
       "         3.0861791e-09, 3.1475886e-09, 3.2905634e-09]],\n",
       "\n",
       "       [[4.3096539e-01, 1.7662259e-03, 1.9458905e-02, ...,\n",
       "         3.0860623e-09, 3.1474696e-09, 3.2904202e-09],\n",
       "        [4.3096545e-01, 1.7662243e-03, 1.9458897e-02, ...,\n",
       "         3.0860683e-09, 3.1474698e-09, 3.2904206e-09],\n",
       "        [4.3096545e-01, 1.7662243e-03, 1.9458897e-02, ...,\n",
       "         3.0860683e-09, 3.1474698e-09, 3.2904206e-09],\n",
       "        ...,\n",
       "        [4.3096545e-01, 1.7662243e-03, 1.9458897e-02, ...,\n",
       "         3.0860683e-09, 3.1474698e-09, 3.2904206e-09],\n",
       "        [4.3096545e-01, 1.7662243e-03, 1.9458897e-02, ...,\n",
       "         3.0860683e-09, 3.1474698e-09, 3.2904206e-09],\n",
       "        [4.3096539e-01, 1.7662259e-03, 1.9458914e-02, ...,\n",
       "         3.0860563e-09, 3.1474696e-09, 3.2904202e-09]]], dtype=float32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 29727)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=test1[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.3095881e-01, 1.7662358e-03, 1.9458774e-02, ..., 3.0862857e-09,\n",
       "       3.1476974e-09, 3.2906771e-09], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3=dict(zip(test2, range(len(test2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sorted(test3.keys(),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3[a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[word for word in word_index if word_index[word]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
