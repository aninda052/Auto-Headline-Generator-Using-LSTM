{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential,Model,save_model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, RepeatVector\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train = load(open('x1_train.pkl','rb'))\n",
    "x2_train = load(open('x2_train.pkl','rb'))\n",
    "y_train = load(open('y_train.pkl','rb'))\n",
    "embedding = load(open('embedding.pkl','rb'))\n",
    "tokenizer = load(open('tokenizer.pkl','rb'))\n",
    "index_to_word = load(open('index_to_word.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247 9 6222\n"
     ]
    }
   ],
   "source": [
    "maxlen_x = len(x1_train[0])\n",
    "maxlen_y = len(x2_train[0])\n",
    "vocab_size = embedding.shape[0]\n",
    "\n",
    "print(maxlen_x,maxlen_y,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_rnn_size = 40 \n",
    "rnn_size = 512 # must be same as 160330-word-gen\n",
    "rnn_layers = 3  # match FN1\n",
    "batch_norm=False\n",
    "seed=42\n",
    "p_W, p_U, p_dense, weight_decay = 0, 0, 0, 0\n",
    "optimizer = 'adam'\n",
    "LR = 1e-4\n",
    "batch_size=64\n",
    "nflips=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer = l2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input1 (InputLayer)             [(None, 1247)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_em (Embedding)             (None, 1247, 200)    1244400     input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "head_em (Embedding)             (None, 9, 200)       1244400     input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "text_drop (Dropout)             (None, 1247, 200)    0           text_em[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "head_drop (Dropout)             (None, 9, 200)       0           head_em[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "text_lstm2 (LSTM)               (None, 12)           10224       text_drop[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "head_lstm1 (LSTM)               (None, 12)           10224       head_drop[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_add (Add)               (None, 12)           0           text_lstm2[0][0]                 \n",
      "                                                                 head_lstm1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dence1 (Dense)          (None, 256)          3328        decoder_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dence2 (Dense)          (None, 6222)         1599054     decoder_dence1[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 4,111,630\n",
      "Trainable params: 4,111,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input1 = Input(shape=(maxlen_x,),name='input1')\n",
    "text_em = Embedding(vocab_size, 200,weights=[embedding],embeddings_regularizer=regularizer,\\\n",
    "                    mask_zero=True,name='text_em')(input1)\n",
    "text_drop=Dropout(.5,name='text_drop')(text_em)\n",
    "#text_lstm1= LSTM(600,activation='relu',return_sequences=True,dropout=.5,kernel_regularizer=regularizer ,name='text_lstm')(text_drop)\n",
    "#text_lstm2= LSTM(30,activation='relu',return_sequences=True,dropout=.5,kernel_regularizer=regularizer ,name='text_lstm1')(text_drop)\n",
    "text_lstm3= LSTM(12,activation='relu',dropout=.5,kernel_regularizer=regularizer ,name='text_lstm2')(text_drop)\n",
    "\n",
    "\n",
    "#encoder13 = RepeatVector(sum_txt_length)(encoder2)\n",
    "\n",
    "input2 = Input(shape=(maxlen_y,),name='input2')\n",
    "head_em = Embedding(vocab_size, 200,weights=[embedding],embeddings_regularizer=regularizer,\\\n",
    "                    mask_zero=True,name='head_em')(input2)\n",
    "head_drop=Dropout(.5,name='head_drop')(head_em)\n",
    "head_lstm1 = LSTM(12,dropout=.5,activation='relu',kernel_regularizer=regularizer ,name='head_lstm1')(head_drop)\n",
    "#head_lstm2= LSTM(30,activation='relu',dropout=.5,kernel_regularizer=regularizer ,name='head_lstm2')(head_lstm1)\n",
    "#encoder23 = RepeatVector(sum_txt_length)(encoder2)\n",
    "\n",
    "decoder_add = add([text_lstm3,head_lstm1],name='decoder_add')\n",
    "decoder_lstm= Dense(256,activation='relu',name='decoder_dence1')(decoder_add)\n",
    "output = Dense(vocab_size, activation='softmax',name='decoder_dence2')(decoder_lstm)\n",
    "# tie it together\n",
    "model = Model(inputs=[input1,input2], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples\n",
      "Epoch 1/20\n",
      "630/630 - 3s - loss: 5.1771\n",
      "Epoch 2/20\n",
      "630/630 - 3s - loss: 5.1658\n",
      "Epoch 3/20\n",
      "630/630 - 3s - loss: 5.1871\n",
      "Epoch 4/20\n",
      "630/630 - 3s - loss: 5.1440\n",
      "Epoch 5/20\n",
      "630/630 - 3s - loss: 5.1435\n",
      "Epoch 6/20\n",
      "630/630 - 3s - loss: 5.1281\n",
      "Epoch 7/20\n",
      "630/630 - 4s - loss: 5.1065\n",
      "Epoch 8/20\n",
      "630/630 - 4s - loss: 5.1090\n",
      "Epoch 9/20\n",
      "630/630 - 4s - loss: 5.0847\n",
      "Epoch 10/20\n",
      "630/630 - 5s - loss: 5.0864\n",
      "Epoch 11/20\n",
      "630/630 - 4s - loss: 5.0593\n",
      "Epoch 12/20\n",
      "630/630 - 4s - loss: 5.0481\n",
      "Epoch 13/20\n",
      "630/630 - 4s - loss: 5.0243\n",
      "Epoch 14/20\n",
      "630/630 - 4s - loss: 5.0228\n",
      "Epoch 15/20\n",
      "630/630 - 4s - loss: 4.9909\n",
      "Epoch 16/20\n",
      "630/630 - 4s - loss: 4.9937\n",
      "Epoch 17/20\n",
      "630/630 - 4s - loss: 4.9827\n",
      "Epoch 18/20\n",
      "630/630 - 4s - loss: 4.9451\n",
      "Epoch 19/20\n",
      "630/630 - 3s - loss: 4.9394\n",
      "Epoch 20/20\n",
      "630/630 - 3s - loss: 4.9027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f774804f710>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1_train,x2_train],y_train,verbose=2,batch_size=200,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aninda/protoTypeProject/nlp/Auto Headline Generator Using LSTM'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "063.txt\n",
      "119.txt\n",
      "043.txt\n",
      "051.txt\n",
      "001.txt\n",
      "183.txt\n",
      "323.txt\n",
      "188.txt\n",
      "057.txt\n",
      "026.txt\n",
      "111.txt\n",
      "037.txt\n",
      "028.txt\n",
      "060.txt\n",
      "207.txt\n"
     ]
    }
   ],
   "source": [
    "test = DataFrame(columns=['Text']) \n",
    "cnt=0\n",
    "for file in os.listdir('./testData'):\n",
    "    test=test.append({'Text':codecs.open('./testData/'+file,encoding='utf8',errors='replace').read()},ignore_index=True)\n",
    "    cnt+=1\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['head_lines']=test['Text'].apply(lambda x: 'startseq '+x.splitlines()[0]+' endseq')\n",
    "test['Text']=test['Text'].apply(lambda x: 'startseq '+' '.join(list(filter(bool,x.splitlines()))[1:])+' endseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence_text=tokenizer.texts_to_sequences(test[\"Text\"].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=pad_sequences([test_sequence_text[10]],maxlen=1247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_description(model,tokenizer,doc,mx_len=9,):\n",
    "    in_text='startseq'\n",
    "\n",
    "    for i in range(mx_len):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=mx_len)\n",
    "        pred = model.predict([doc,sequence], verbose=0)\n",
    "        pred = argmax(pred)\n",
    "        print(pred)\n",
    "        pred_word = index_to_word[pred]\n",
    "        in_text += ' '+pred_word\n",
    "        if pred_word == 'endseq' or pred_word is None:\n",
    "            break\n",
    "    in_text=' '.join(in_text.split()[1:-1])\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "9\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "a=pred_description(model,tokenizer,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to to for'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
